{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMWp3bQP-bhU"
   },
   "source": [
    "# Lab 5 - Classification : Naive Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-5YUdzFsqwL"
   },
   "source": [
    "# Optical recognition of handwritten digits dataset\n",
    "**Download dataset from sklearn. The dataset has 10 classes and 64 attributes (8x8 images). Visualise images from the dataset. Perform a train test split in the ratio 4:1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6w_FSrzBE5pw"
   },
   "source": [
    "# Using sklearn (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANyyLqRaE-RA"
   },
   "source": [
    "**For this exercise, you will use the naive bayes and logistic regression functions in sklearn. Use the optical recognition dataset.**\n",
    "\n",
    "\n",
    "**a) Logistic Regression - use one vs all classification method to classify the dataset into one of the ten classes. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too). Tune parameters to obtain the best results.**\n",
    "\n",
    "**b) Naive Bayes - perform multiclass classification to classify the dataset into one of the ten classes. Experiment with all the priors available (Gaussian, Bernoulli, etc) and report the best prior. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too).**\n",
    "\n",
    "**Estimated Time: 50 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvL8quVdN24q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images in the dataset are as follows :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# loading the dataset\n",
    "Digits = load_digits()\n",
    "\n",
    "# visualizing the data\n",
    "print(\"The images in the dataset are as follows :\")\n",
    "# plotting\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(Digits.images[i],cmap=plt.cm.gray_r)\n",
    "    plt.axis('off')\n",
    "    plt.title(str(Digits.target[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the original dataset is (1797, 64)\n",
      "The dimension of the training data is:  (1437, 64)\n",
      "The dimension of the test data is:  (360, 64)\n",
      "\n",
      "===============train - test splitting done ============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and testing splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Digits.data, Digits.target, test_size = 0.2, random_state = 0)\n",
    "# Ensuring correct splitting\n",
    "print('The dimension of the original dataset is', Digits.data.shape)\n",
    "print(\"The dimension of the training data is: \", X_train.shape)\n",
    "print(\"The dimension of the test data is: \", X_test.shape)\n",
    "print(\"\\n===============train - test splitting done ============\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a - part) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.9500000000000001\n",
      "\n",
      "Confusion matrix : \n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 31  0  0  0  0  1  0  3  0]\n",
      " [ 0  0 34  2  0  0  0  0  0  0]\n",
      " [ 0  0  0 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 43  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 37  0  0]\n",
      " [ 0  2  1  0  0  0  0  0 35  1]\n",
      " [ 0  0  0  1  0  1  0  0  2 37]]\n",
      "\n",
      "The number of mislabeled points out of 360 points : 18\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression without tuning\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "Y_pred = LogReg.predict(X_test)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score :\")\n",
    "print(metrics.f1_score(Y_test,Y_pred,average = \"micro\"))   # since it is a multiclass problem, we should specify average = micro\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion matrix : \")\n",
    "print(metrics.confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "# mislabeled points\n",
    "print(\"\\nThe number of mislabeled points out of \"+str(len(X_test))+\" points :\",(Y_test != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal C value is : 0.09102981779915217\n"
     ]
    }
   ],
   "source": [
    "# Tuning the parameters using GridsearchCV\n",
    "range_c = np.logspace(-3,3,50)\n",
    "parameters = {'C': range_c}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv = 5)\n",
    "clf.fit(X_train,Y_train)\n",
    "print(\"The optimal C value is :\", clf.best_params_['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.9583333333333334\n",
      "\n",
      "Confusion matrix : \n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 33  0  0  0  0  1  0  1  0]\n",
      " [ 0  0 35  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 43  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 37  0  0]\n",
      " [ 0  2  1  0  0  0  0  0 36  0]\n",
      " [ 0  0  0  1  0  1  0  0  3 36]]\n",
      "\n",
      "Classification report for logistic regression classifier \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.89      0.94      0.92        35\n",
      "           2       0.97      0.97      0.97        36\n",
      "           3       0.94      1.00      0.97        29\n",
      "           4       0.97      1.00      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       0.98      0.98      0.98        44\n",
      "           7       1.00      0.95      0.97        39\n",
      "           8       0.90      0.92      0.91        39\n",
      "           9       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "\n",
      "The number of mislabeled points out of 360 points : 15\n"
     ]
    }
   ],
   "source": [
    "# For the best parameters found, applying logistic regression\n",
    "LogReg = LogisticRegression(C = clf.best_params_['C'])\n",
    "LogReg.fit(X_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "Y_pred = LogReg.predict(X_test)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score :\")\n",
    "print(metrics.f1_score(Y_test,Y_pred,average = \"micro\"))   # since it is a multiclass problem, we should specify average = micro\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion matrix : \")\n",
    "print(metrics.confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(\"\\nClassification report for logistic regression classifier \\n\")\n",
    "print((metrics.classification_report(Y_test, Y_pred)))\n",
    "\n",
    "# mislabeled points\n",
    "print(\"\\nThe number of mislabeled points out of \"+str(len(X_test))+\" points :\",(Y_test != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results :\n",
    "\n",
    "- Logistic regression is performing very well on the given dataset, after tuning the inverse of regularization parameter,C \n",
    "    - f1 score = 0.9583\n",
    "    - 15 images are mislabeled, out of 360 in test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.825\n",
      "\n",
      "Confusion matrix : \n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  4  0]\n",
      " [ 0  7 17  0  0  0  0  0 12  0]\n",
      " [ 0  0  1 24  0  0  0  0  4  0]\n",
      " [ 0  1  0  0 22  0  0  7  0  0]\n",
      " [ 0  1  0  0  0 35  0  3  0  1]\n",
      " [ 0  0  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  5  0  0  0  1  0  1 32  0]\n",
      " [ 0  2  0  3  0  0  0  3  7 26]]\n",
      "\n",
      "The number of mislabeled points out of 360 points : 63\n"
     ]
    }
   ],
   "source": [
    "# Gaussian prior\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "Gnb = GaussianNB()\n",
    "Gnb.fit(X_train,Y_train)\n",
    "# prediction\n",
    "Y_pred = Gnb.predict(X_test)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score :\")\n",
    "print(metrics.f1_score(Y_test,Y_pred,average = \"micro\"))   # since it is a multiclass problem, we should specify average = micro\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion matrix : \")\n",
    "print(metrics.confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "# mislabeled points\n",
    "print(\"\\nThe number of mislabeled points out of \"+str(len(X_test))+\" points :\",(Y_test != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.9083333333333333\n",
      "\n",
      "Confusion matrix : \n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 25  6  0  0  1  0  0  0  3]\n",
      " [ 1  2 31  0  0  0  0  0  1  1]\n",
      " [ 0  0  1 26  0  0  0  0  1  1]\n",
      " [ 0  0  0  0 29  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 34  0  0  0  6]\n",
      " [ 0  0  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  3  0  0  0  0  0  1 35  0]\n",
      " [ 0  0  0  0  0  0  0  3  1 37]]\n",
      "\n",
      "The number of mislabeled points out of 360 points : 33\n"
     ]
    }
   ],
   "source": [
    "# Multinomial prior\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Mnb = MultinomialNB()\n",
    "Mnb.fit(X_train,Y_train)\n",
    "# prediction\n",
    "Y_pred = Mnb.predict(X_test)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score :\")\n",
    "print(metrics.f1_score(Y_test,Y_pred,average = \"micro\"))   # since it is a multiclass problem, we should specify average = micro\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion matrix : \")\n",
    "print(metrics.confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "# mislabeled points\n",
    "print(\"\\nThe number of mislabeled points out of \"+str(len(X_test))+\" points :\",(Y_test != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      "0.8444444444444444\n",
      "\n",
      "Confusion matrix : \n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 20  8  0  0  0  0  0  5  2]\n",
      " [ 0  1 29  4  0  0  0  1  1  0]\n",
      " [ 0  0  1 25  0  0  0  0  1  2]\n",
      " [ 0  0  0  0 28  0  0  2  0  0]\n",
      " [ 1  1  0  1  0 32  0  0  0  5]\n",
      " [ 0  1  0  0  1  1 41  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  4  0  1  0  0  0  1 31  2]\n",
      " [ 0  0  0  3  2  1  0  2  1 32]]\n",
      "\n",
      "The number of mislabeled points out of 360 points : 56\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli prior\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "Bnb = BernoulliNB()\n",
    "Bnb.fit(X_train,Y_train)\n",
    "# prediction\n",
    "Y_pred = Bnb.predict(X_test)\n",
    "\n",
    "# F1 score\n",
    "print(\"F1 score :\")\n",
    "print(metrics.f1_score(Y_test,Y_pred,average = \"micro\"))   # since it is a multiclass problem, we should specify average = micro\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion matrix : \")\n",
    "print(metrics.confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "# mislabeled points\n",
    "print(\"\\nThe number of mislabeled points out of \"+str(len(X_test))+\" points :\",(Y_test != Y_pred).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oli7OP9XN4ZF"
   },
   "source": [
    "# Observations :\n",
    "\n",
    "- Using multinomial prior, we get the best f1 score of 0.9083 , compared to Gaussian prior(0.825) and Bernoulli prior (0.8444). \n",
    "- So, Multinomial prior is the best prior.\n",
    "- Bernoulli prior is better than gaussian prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aiq6KaGLOAba"
   },
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab5_DataAnalytics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
